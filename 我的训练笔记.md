背景

我决定针对online_demo里用到的mobilenet_v2_tsm进行迁移训练，因为我想增加，或者替换成新的手势，比如打响指，画圆圈。

过程

1. 下载预训练模型，README里有下载链接：![image-20210413144020874](https://gitlab.com/wwdok/my-image-bed/-/raw/master/pictures/2021/04/13_14_40_30_image-20210413144020874.png)

[what does 8*10 clips means?](https://github.com/mit-han-lab/temporal-shift-module/issues/126)

2. 设置命令行参数：scripts文件里是一些命令行脚本，拷贝`finetune_tsm_ucf101_rgb_8f.sh`，并重命名为`finetune_tsm_kinetics_rgb_8f.sh`。里面有很多参数，这些参数的名称可以在opts.py里找到更详细的说明，比如`--gd`的详细说明是：

```
parser.add_argument('--clip-gradient', '--gd', default=None, type=float,
                    metavar='W', help='gradient norm clipping (default: disabled)')
```

还是看不懂，但我看其他训练脚本这个值都是20，那我也默认它20好了。

根据你的训练机器，修改 `--batch-size`  和 `-j`。

`--tune_from`指向上面下载的预训练模型

3. 下载jester数据集：去twentybn网站[下载jester v1数据集](https://20bn.com/datasets/download)，下载完22G的压缩包，如果你是linux系统，网站上说执行`cat 20bn-jester-v1-?? | tar zx`解压，但这在windows系统的电脑上行不通，我用7zip解压软件也不行，解决办法是[这里](https://stackoverflow.com/a/66363714/12169382)说的打开git bash输入上述命令。你可能看不到命令行窗口没有任何输出，但任务管理器可以看到磁盘写入速度有20M/s，进入20bn-jester-v1文件夹，发现里面的项目数一直在增加，说明我们的数据集正在正常解压！最后整个解压差不多花了半个小时！解压后的文件夹结构可能不合理想，你想重构，建议不要使用Ctrl X + Ctrl V，这样资源管理器容易卡死，建议直接拖动文件夹到想要的根目录下。

4. 下载下来的标签文件是csv，我们需要转换成本仓库要求的txt，里面的格式是什么样的呢，从dataset.py的class VideoRecord 和 def _parse_list 可以看出txt里每行的内容是图片路径，图片张数，手势标签id。复制tools文件夹下的gen_label_sthv1.py，重命名为gen_label_jesterv1.py，里面的内容修改为：

```python
"""
将下载下来的4个csv文件放在tools文件夹下面
直接在本文件右击Run运行，无需在根目录下运行
将生成的3个txt文件剪切到dataset/jester文件夹下
"""
import os

if __name__ == '__main__':
    dataset_name = 'jester-v1'
    with open('%s-labels.csv' % dataset_name) as f:
        lines = f.readlines()
    categories = []
    for line in lines:
        line = line.rstrip()
        categories.append(line)
    categories = sorted(categories)  # 这句代码会让生成的category.txt里的标签顺序跟csv里的不一样
    with open('../dataset/jester/category.txt', 'w') as f:
        f.write('\n'.join(categories))

    dict_categories = {}
    for i, category in enumerate(categories):
        dict_categories[category] = i

    files_input = ['%s-validation.csv' % dataset_name, '%s-train.csv' % dataset_name]
    files_output = ['val_videofolder.txt', 'train_videofolder.txt']
    for (filename_input, filename_output) in zip(files_input, files_output):
        with open(filename_input) as f:
            lines = f.readlines()
        folders = []
        idx_categories = []
        for line in lines:
            line = line.rstrip()
            items = line.split(';')  # jester提供的csv里面文件夹名称和手势标签名称是通过;分隔的
            folders.append(items[0])  # folders存的是一串代表文件夹名的数字，范围从1到148092
            idx_categories.append(dict_categories[items[1]])  # idx_categories存的是一串代表手势id的数字，避免了名称长单词之间有空格，范围从0到26
        output = []
        for i in range(len(folders)):
            curFolder = folders[i]
            curIDX = idx_categories[i]
            # counting the number of frames in each video folders
            dir_files = os.listdir(os.path.join('../dataset/jester/20bn-jester-v1', curFolder))

            # 后面代码会在'jester/20bn-jester-v1/'前面接上ROOT_DATASET = './dataset/'
            output.append('%s %d %d' % ('jester/20bn-jester-v1/' + curFolder, len(dir_files), curIDX))  # txt文件里每行的内容
            print('%d/%d' % (i, len(folders)))
        with open(filename_output, 'w') as f:
            f.write('\n'.join(output))
```

最后的文件夹结构如下：

![image-20210414160438096](https://gitlab.com/wwdok/my-image-bed/-/raw/master/pictures/2021/04/14_16_4_39_image-20210414160438096.png)



5. 为了训练mobilenet_v2_TSM，我对源代码改了3个地方，所以本仓库是专门的，运行下面的命令启动训练：

E:\Repo\VideoUnderstanding\temporal-shift-module (master)
bash "E:\Repo\VideoUnderstanding\temporal-shift-module\scripts\finetune_tsm_kinetics_rgb_8f.sh"



训练开始后会告诉你state_dict keys不匹配，相关代码在main.py的 `if args.tune_from:`代码块，因为里面的model指的是TSN，而我们的权重是TSM，两种截然不同的模型，state_dict keys不匹配应该算很正常吧。



TSM MoileNetV2的[test log](https://file.lzhu.me/projects/tsm/models/log/testlog_TSM_kinetics_RGB_mobilenetv2_shift8_blockres_avg_segment8_e100_dense.log)部分内容如下：

```
! python test_models.py kinetics \
    --weights=TSM_kinetics_RGB_mobilenetv2_shift8_blockres_avg_segment8_e100_dense.pth \
    --test_segments=8 --batch_size=8 -j 24 --full_res --test_crops=3 --dense_sample \
    --only_even_indice

=> shift: True, shift_div: 8, shift_place: blockres

    Initializing TSN with base model: mobilenetv2.
    TSN Configurations:
        input_modality:     RGB
        num_segments:       8
        new_length:         1
        consensus_module:   avg
        dropout_ratio:      0.5
        img_feature_dim:    256

=> base model: mobilenetv2
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Adding temporal shift... True
=> Using fold div: 4, n_segment: 8, kernel: 3
Non-supported OP type: [<class 'torch.nn.modules.batchnorm.BatchNorm2d'>, <class 'torch.nn.modules.activation.ReLU6'>, <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>, <class 'ops.basic_ops.ConsensusModule'>]
Freezing BatchNorm2D except the first one.
=> FLOPs: 2.400G, param: 2.736M
=> Using dense sample for the dataset...                                                                                                                       
=> Removing missing...
video number:19654
video 0 done, total 0/19654, average 6.385 sec/video, moving Prec@1 75.000 Prec@5 100.000
video 160 done, total 160/19654, average 0.323 sec/video, moving Prec@1 52.381 Prec@5 85.119
video 320 done, total 320/19654, average 0.186 sec/video, moving Prec@1 56.707 Prec@5 80.488
video 480 done, total 480/19654, average 0.170 sec/video, moving Prec@1 67.828 Prec@5 86.475
video 640 done, total 640/19654, average 0.156 sec/video, moving Prec@1 70.525 Prec@5 87.963
video 800 done, total 800/19654, average 0.154 sec/video, moving Prec@1 70.545 Prec@5 87.871
video 960 done, total 960/19654, average 0.132 sec/video, moving Prec@1 71.798 Prec@5 88.326
```

可以看出Prec@1和Prec@5代表一个前1个预测结果准确的准确的准确率 和 前5个预测结果有一个准确的准确率。

我们的训练也可以参照该值判断训练结果的好坏。

